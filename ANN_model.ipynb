{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d003e799",
   "metadata": {},
   "source": [
    "# CHURN MODELLING USING ARTIFICIAL NUERAL NETWORKS (DEEP LEARNING MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f50492",
   "metadata": {},
   "source": [
    "## 1) Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8de49384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76b652df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Churn_Modelling.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d5b3260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 14)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2269f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['RowNumber','CustomerId','Surname'],inplace=True) #Removing unwanted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38e89d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "324fbff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 11)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00917be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'CreditScore'}>,\n",
       "        <AxesSubplot:title={'center':'Age'}>,\n",
       "        <AxesSubplot:title={'center':'Tenure'}>],\n",
       "       [<AxesSubplot:title={'center':'Balance'}>,\n",
       "        <AxesSubplot:title={'center':'NumOfProducts'}>,\n",
       "        <AxesSubplot:title={'center':'HasCrCard'}>],\n",
       "       [<AxesSubplot:title={'center':'IsActiveMember'}>,\n",
       "        <AxesSubplot:title={'center':'EstimatedSalary'}>,\n",
       "        <AxesSubplot:title={'center':'Exited'}>]], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.hist() #Plotting histogram of each features\n",
    "\n",
    "#Credit Score Column is almost normally distributed\n",
    "# Age Column is left skewed\n",
    "#Estimated Salary is uniform distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12a7e471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore          int64\n",
       "Geography           object\n",
       "Gender              object\n",
       "Age                  int64\n",
       "Tenure               int64\n",
       "Balance            float64\n",
       "NumOfProducts        int64\n",
       "HasCrCard            int64\n",
       "IsActiveMember       int64\n",
       "EstimatedSalary    float64\n",
       "Exited               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a5ede9",
   "metadata": {},
   "source": [
    "## 2)Converting categorical data into numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce9e1e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Gender'] = pd.get_dummies(data['Gender'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "772d96c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['France','Germany','Spain']] = pd.get_dummies(data['Geography'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7506f573",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns='Geography',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "600c46d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0             619       0   42       2       0.00              1          1   \n",
       "1             608       0   41       1   83807.86              1          0   \n",
       "2             502       0   42       8  159660.80              3          1   \n",
       "3             699       0   39       1       0.00              2          0   \n",
       "4             850       0   43       2  125510.82              1          1   \n",
       "...           ...     ...  ...     ...        ...            ...        ...   \n",
       "9995          771       1   39       5       0.00              2          1   \n",
       "9996          516       1   35      10   57369.61              1          1   \n",
       "9997          709       0   36       7       0.00              1          0   \n",
       "9998          772       1   42       3   75075.31              2          1   \n",
       "9999          792       0   28       4  130142.79              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Exited  France  Germany  Spain  \n",
       "0                  1        101348.88       1       1        0      0  \n",
       "1                  1        112542.58       0       0        0      1  \n",
       "2                  0        113931.57       1       1        0      0  \n",
       "3                  0         93826.63       0       1        0      0  \n",
       "4                  1         79084.10       0       0        0      1  \n",
       "...              ...              ...     ...     ...      ...    ...  \n",
       "9995               0         96270.64       0       1        0      0  \n",
       "9996               1        101699.77       0       1        0      0  \n",
       "9997               1         42085.58       1       1        0      0  \n",
       "9998               0         92888.52       1       0        1      0  \n",
       "9999               0         38190.78       0       1        0      0  \n",
       "\n",
       "[10000 rows x 13 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665cb73f",
   "metadata": {},
   "source": [
    "# CASE 1: WITHOUT STANDARDIZING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4612a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619       0   42       2       0.00              1          1   \n",
       "1          608       0   41       1   83807.86              1          0   \n",
       "2          502       0   42       8  159660.80              3          1   \n",
       "3          699       0   39       1       0.00              2          0   \n",
       "4          850       0   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  France  Germany  Spain  \n",
       "0               1        101348.88       1       1        0      0  \n",
       "1               1        112542.58       0       0        0      1  \n",
       "2               0        113931.57       1       1        0      0  \n",
       "3               0         93826.63       0       1        0      0  \n",
       "4               1         79084.10       0       0        0      1  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79847f46",
   "metadata": {},
   "source": [
    "## 3) Extracting into features and label sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e77e72a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619       0   42       2       0.00              1          1   \n",
       "1          608       0   41       1   83807.86              1          0   \n",
       "2          502       0   42       8  159660.80              3          1   \n",
       "3          699       0   39       1       0.00              2          0   \n",
       "4          850       0   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  France  Germany  Spain  \n",
       "0               1        101348.88       1        0      0  \n",
       "1               1        112542.58       0        0      1  \n",
       "2               0        113931.57       1        0      0  \n",
       "3               0         93826.63       1        0      0  \n",
       "4               1         79084.10       0        0      1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.drop(columns='Exited')\n",
    "Y = data['Exited']\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "071d5349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    0\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ed345e",
   "metadata": {},
   "source": [
    "## 4) Splitting the data into training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d4ebf978",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2,random_state=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63042ebf",
   "metadata": {},
   "source": [
    "## 5) Building a sequential dense nueral network for predicting the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07ac239e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(256,input_dim = 12, activation='relu')) # 1st layer contains 256 nuerons with input as 12 features\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(128,activation='relu')) #2 layer contains 128 nuerons\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(64,activation='relu'))  #2 layer contains 64 nuerons\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(32,activation='relu'))  #2 layer contains 32 nuerons\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(16,activation='relu'))  #2 layer contains 16 nuerons\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))  #Output layer with sigmoid as activation function\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])  #Compiling the model with optimizer as adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "11d28d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5796 - accuracy: 0.7261 - val_loss: 0.5352 - val_accuracy: 0.7875\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5058 - accuracy: 0.7981 - val_loss: 0.5169 - val_accuracy: 0.7850\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5007 - accuracy: 0.7981 - val_loss: 0.5098 - val_accuracy: 0.7890\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4980 - accuracy: 0.7981 - val_loss: 0.5085 - val_accuracy: 0.7890\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4984 - accuracy: 0.7981 - val_loss: 0.5083 - val_accuracy: 0.7890\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4967 - accuracy: 0.7981 - val_loss: 0.5150 - val_accuracy: 0.7890\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4972 - accuracy: 0.7981 - val_loss: 0.5106 - val_accuracy: 0.7890\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4965 - accuracy: 0.7981 - val_loss: 0.5089 - val_accuracy: 0.7890\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4971 - accuracy: 0.7981 - val_loss: 0.5089 - val_accuracy: 0.7890\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4962 - accuracy: 0.7981 - val_loss: 0.5110 - val_accuracy: 0.7890\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4963 - accuracy: 0.7981 - val_loss: 0.5128 - val_accuracy: 0.7890\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4971 - accuracy: 0.7981 - val_loss: 0.5091 - val_accuracy: 0.7890\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4973 - accuracy: 0.7981 - val_loss: 0.5110 - val_accuracy: 0.7890\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4972 - accuracy: 0.7981 - val_loss: 0.5104 - val_accuracy: 0.7890\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4953 - accuracy: 0.7981 - val_loss: 0.5110 - val_accuracy: 0.7890\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4972 - accuracy: 0.7981 - val_loss: 0.5086 - val_accuracy: 0.7890\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4957 - accuracy: 0.7981 - val_loss: 0.5113 - val_accuracy: 0.7890\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4961 - accuracy: 0.7981 - val_loss: 0.5105 - val_accuracy: 0.7890\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4967 - accuracy: 0.7981 - val_loss: 0.5084 - val_accuracy: 0.7890\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4967 - accuracy: 0.7981 - val_loss: 0.5084 - val_accuracy: 0.7890\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4964 - accuracy: 0.7981 - val_loss: 0.5093 - val_accuracy: 0.7890\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4958 - accuracy: 0.7981 - val_loss: 0.5120 - val_accuracy: 0.7890\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4964 - accuracy: 0.7981 - val_loss: 0.5104 - val_accuracy: 0.7890\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4957 - accuracy: 0.7981 - val_loss: 0.5100 - val_accuracy: 0.7890\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4964 - accuracy: 0.7981 - val_loss: 0.5096 - val_accuracy: 0.7890\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4952 - accuracy: 0.7981 - val_loss: 0.5104 - val_accuracy: 0.7890\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4964 - accuracy: 0.7981 - val_loss: 0.5108 - val_accuracy: 0.7890\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4963 - accuracy: 0.7981 - val_loss: 0.5107 - val_accuracy: 0.7890\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4957 - accuracy: 0.7981 - val_loss: 0.5088 - val_accuracy: 0.7890\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4958 - accuracy: 0.7981 - val_loss: 0.5093 - val_accuracy: 0.7890\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4961 - accuracy: 0.7981 - val_loss: 0.5092 - val_accuracy: 0.7890\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4955 - accuracy: 0.7981 - val_loss: 0.5092 - val_accuracy: 0.7890\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4964 - accuracy: 0.7981 - val_loss: 0.5090 - val_accuracy: 0.7890\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4960 - accuracy: 0.7981 - val_loss: 0.5100 - val_accuracy: 0.7890\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4960 - accuracy: 0.7981 - val_loss: 0.5106 - val_accuracy: 0.7890\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4953 - accuracy: 0.7981 - val_loss: 0.5103 - val_accuracy: 0.7890\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4955 - accuracy: 0.7981 - val_loss: 0.5099 - val_accuracy: 0.7890\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4963 - accuracy: 0.7981 - val_loss: 0.5094 - val_accuracy: 0.7890\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4960 - accuracy: 0.7981 - val_loss: 0.5093 - val_accuracy: 0.7890\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4955 - accuracy: 0.7981 - val_loss: 0.5123 - val_accuracy: 0.7890\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4953 - accuracy: 0.7981 - val_loss: 0.5087 - val_accuracy: 0.7890\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4958 - accuracy: 0.7981 - val_loss: 0.5119 - val_accuracy: 0.7890\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4961 - accuracy: 0.7981 - val_loss: 0.5106 - val_accuracy: 0.7890\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4954 - accuracy: 0.7981 - val_loss: 0.5115 - val_accuracy: 0.7890\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4957 - accuracy: 0.7981 - val_loss: 0.5106 - val_accuracy: 0.7890\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4965 - accuracy: 0.7981 - val_loss: 0.5094 - val_accuracy: 0.7890\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4963 - accuracy: 0.7981 - val_loss: 0.5099 - val_accuracy: 0.7890\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4964 - accuracy: 0.7981 - val_loss: 0.5096 - val_accuracy: 0.7890\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4959 - accuracy: 0.7981 - val_loss: 0.5107 - val_accuracy: 0.7890\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4961 - accuracy: 0.7981 - val_loss: 0.5105 - val_accuracy: 0.7890\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4948 - accuracy: 0.7981 - val_loss: 0.5087 - val_accuracy: 0.7890\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4945 - accuracy: 0.7981 - val_loss: 0.5104 - val_accuracy: 0.7890\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4959 - accuracy: 0.7981 - val_loss: 0.5092 - val_accuracy: 0.7890\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4951 - accuracy: 0.7981 - val_loss: 0.5103 - val_accuracy: 0.7890\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4950 - accuracy: 0.7981 - val_loss: 0.5078 - val_accuracy: 0.7890\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4950 - accuracy: 0.7981 - val_loss: 0.5092 - val_accuracy: 0.7890\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4948 - accuracy: 0.7981 - val_loss: 0.5079 - val_accuracy: 0.7890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4949 - accuracy: 0.7981 - val_loss: 0.5098 - val_accuracy: 0.7890\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4951 - accuracy: 0.7981 - val_loss: 0.5085 - val_accuracy: 0.7890\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4947 - accuracy: 0.7981 - val_loss: 0.5099 - val_accuracy: 0.7890\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4946 - accuracy: 0.7981 - val_loss: 0.5090 - val_accuracy: 0.7890\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4952 - accuracy: 0.7981 - val_loss: 0.5073 - val_accuracy: 0.7890\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4944 - accuracy: 0.7981 - val_loss: 0.5206 - val_accuracy: 0.7890\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4943 - accuracy: 0.7981 - val_loss: 0.5100 - val_accuracy: 0.7890\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4948 - accuracy: 0.7981 - val_loss: 0.5106 - val_accuracy: 0.7890\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4946 - accuracy: 0.7981 - val_loss: 0.5115 - val_accuracy: 0.7890\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4950 - accuracy: 0.7981 - val_loss: 0.5105 - val_accuracy: 0.7890\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4948 - accuracy: 0.7981 - val_loss: 0.5165 - val_accuracy: 0.7890\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4938 - accuracy: 0.7981 - val_loss: 0.5160 - val_accuracy: 0.7890\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4943 - accuracy: 0.7981 - val_loss: 0.5107 - val_accuracy: 0.7890\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4945 - accuracy: 0.7981 - val_loss: 0.5073 - val_accuracy: 0.7890\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4943 - accuracy: 0.7981 - val_loss: 0.5439 - val_accuracy: 0.7890\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4955 - accuracy: 0.7981 - val_loss: 0.5195 - val_accuracy: 0.7890\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4941 - accuracy: 0.7981 - val_loss: 0.5138 - val_accuracy: 0.7890\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4954 - accuracy: 0.7981 - val_loss: 0.5301 - val_accuracy: 0.7890\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4946 - accuracy: 0.7981 - val_loss: 0.5113 - val_accuracy: 0.7890\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4933 - accuracy: 0.7981 - val_loss: 0.5307 - val_accuracy: 0.7890\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4955 - accuracy: 0.7981 - val_loss: 0.5141 - val_accuracy: 0.7890\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4949 - accuracy: 0.7981 - val_loss: 0.5104 - val_accuracy: 0.7890\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4958 - accuracy: 0.7981 - val_loss: 0.5100 - val_accuracy: 0.7890\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4943 - accuracy: 0.7981 - val_loss: 0.5105 - val_accuracy: 0.7890\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4950 - accuracy: 0.7981 - val_loss: 0.5113 - val_accuracy: 0.7890\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4955 - accuracy: 0.7981 - val_loss: 0.5113 - val_accuracy: 0.7890\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4939 - accuracy: 0.7981 - val_loss: 0.5121 - val_accuracy: 0.7890\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4946 - accuracy: 0.7981 - val_loss: 0.5123 - val_accuracy: 0.7885\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4950 - accuracy: 0.7981 - val_loss: 0.5093 - val_accuracy: 0.7885\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4961 - accuracy: 0.7981 - val_loss: 0.5097 - val_accuracy: 0.7885\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4957 - accuracy: 0.7981 - val_loss: 0.5100 - val_accuracy: 0.7890\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4948 - accuracy: 0.7981 - val_loss: 0.5101 - val_accuracy: 0.7890\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4949 - accuracy: 0.7981 - val_loss: 0.5090 - val_accuracy: 0.7890\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4950 - accuracy: 0.7981 - val_loss: 0.5100 - val_accuracy: 0.7890\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4950 - accuracy: 0.7981 - val_loss: 0.5093 - val_accuracy: 0.7890\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4939 - accuracy: 0.7981 - val_loss: 0.5104 - val_accuracy: 0.7890\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4948 - accuracy: 0.7981 - val_loss: 0.5091 - val_accuracy: 0.7890\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4954 - accuracy: 0.7981 - val_loss: 0.5091 - val_accuracy: 0.7890\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4953 - accuracy: 0.7981 - val_loss: 0.5097 - val_accuracy: 0.7890\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4955 - accuracy: 0.7981 - val_loss: 0.5106 - val_accuracy: 0.7890\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4949 - accuracy: 0.7981 - val_loss: 0.5132 - val_accuracy: 0.7860\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4955 - accuracy: 0.7981 - val_loss: 0.5093 - val_accuracy: 0.7885\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4958 - accuracy: 0.7981 - val_loss: 0.5102 - val_accuracy: 0.7890\n"
     ]
    }
   ],
   "source": [
    "#Fitting the model with the training data and validation with testing data\n",
    "# Setting epochs = 100\n",
    "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b122c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.798, Test: 0.789\n"
     ]
    }
   ],
   "source": [
    "#Checking the model accuracy\n",
    "\n",
    "_, train_acc = model.evaluate(X_train, Y_train, verbose=0)\n",
    "_, test_acc = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b04991",
   "metadata": {},
   "source": [
    "## From this we see that model is close to good fit model which fits quite well with both training and testing data. But its performance should be improved more for better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff9e261",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051f4430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58989b08",
   "metadata": {},
   "source": [
    "# CASE 2: STANDARDIZING THE DATA AND THEN BUILDING DEEP NUERAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3d6cc0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the creditscore, balance, estimatedsalary columns as they are not normalized\n",
    "\n",
    "sc = StandardScaler()\n",
    "data[['CreditScore','Balance','EstimatedSalary']] = sc.fit_transform(data[['CreditScore','Balance','EstimatedSalary']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c146a10c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.326221</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.021886</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.440036</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>0.117350</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.216534</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.536794</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>1.333053</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.240687</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.501521</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.108918</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.063884</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>0.785728</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.365276</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Gender  Age  Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "0    -0.326221       0   42       2 -1.225848              1          1   \n",
       "1    -0.440036       0   41       1  0.117350              1          0   \n",
       "2    -1.536794       0   42       8  1.333053              3          1   \n",
       "3     0.501521       0   39       1 -1.225848              2          0   \n",
       "4     2.063884       0   43       2  0.785728              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  France  Germany  Spain  \n",
       "0               1         0.021886       1       1        0      0  \n",
       "1               1         0.216534       0       0        0      1  \n",
       "2               0         0.240687       1       1        0      0  \n",
       "3               0        -0.108918       0       1        0      0  \n",
       "4               1        -0.365276       0       0        0      1  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2251cd6d",
   "metadata": {},
   "source": [
    "## 3) Extracting into features and label sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "960ee66f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.326221</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.021886</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.440036</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>0.117350</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.216534</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.536794</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>1.333053</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.240687</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.501521</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.108918</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.063884</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>0.785728</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.365276</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Gender  Age  Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "0    -0.326221       0   42       2 -1.225848              1          1   \n",
       "1    -0.440036       0   41       1  0.117350              1          0   \n",
       "2    -1.536794       0   42       8  1.333053              3          1   \n",
       "3     0.501521       0   39       1 -1.225848              2          0   \n",
       "4     2.063884       0   43       2  0.785728              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  France  Germany  Spain  \n",
       "0               1         0.021886       1        0      0  \n",
       "1               1         0.216534       0        0      1  \n",
       "2               0         0.240687       1        0      0  \n",
       "3               0        -0.108918       1        0      0  \n",
       "4               1        -0.365276       0        0      1  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.drop(columns='Exited')\n",
    "Y = data['Exited']\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b44e5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    0\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91615f66",
   "metadata": {},
   "source": [
    "## 4) Splitting the data into training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6271e2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2,random_state=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b03e788",
   "metadata": {},
   "source": [
    "## 5) Building a sequential dense nueral network for predicting the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "140c2f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(256,input_dim = 12, activation='relu')) # 1st layer contains 256 nuerons with input as 12 features\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(128,activation='relu')) #2nd layer contains 128 nuerons\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(64,activation='relu'))  #3rd layer contains 64 nuerons\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(32,activation='relu'))  #4th layer contains 32 nuerons\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(16,activation='relu'))  #5th layer contains 16 nuerons\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))  #Output layer with sigmoid as activation function\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])  #Compiling the model with optimizer as adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "73e19e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5372 - accuracy: 0.7545 - val_loss: 0.4736 - val_accuracy: 0.7975\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4181 - accuracy: 0.8235 - val_loss: 0.5500 - val_accuracy: 0.7490\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3900 - accuracy: 0.8403 - val_loss: 0.4868 - val_accuracy: 0.7985\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3737 - accuracy: 0.8460 - val_loss: 0.4119 - val_accuracy: 0.8240\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3637 - accuracy: 0.8516 - val_loss: 0.4121 - val_accuracy: 0.8235\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3630 - accuracy: 0.8482 - val_loss: 0.3816 - val_accuracy: 0.8430\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3617 - accuracy: 0.8484 - val_loss: 0.3786 - val_accuracy: 0.8450\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3523 - accuracy: 0.8521 - val_loss: 0.4126 - val_accuracy: 0.8275\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3559 - accuracy: 0.8506 - val_loss: 0.3709 - val_accuracy: 0.8475\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3546 - accuracy: 0.8526 - val_loss: 0.4473 - val_accuracy: 0.7880\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3487 - accuracy: 0.8515 - val_loss: 0.3816 - val_accuracy: 0.8540\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3491 - accuracy: 0.8565 - val_loss: 0.3557 - val_accuracy: 0.8570\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3462 - accuracy: 0.8549 - val_loss: 0.3638 - val_accuracy: 0.8540\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3459 - accuracy: 0.8576 - val_loss: 0.3888 - val_accuracy: 0.8425\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3462 - accuracy: 0.8565 - val_loss: 0.4508 - val_accuracy: 0.8165\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3431 - accuracy: 0.8534 - val_loss: 0.3861 - val_accuracy: 0.8405\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3405 - accuracy: 0.8581 - val_loss: 0.3716 - val_accuracy: 0.8455\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3414 - accuracy: 0.8604 - val_loss: 0.3877 - val_accuracy: 0.8410\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3446 - accuracy: 0.8550 - val_loss: 0.3599 - val_accuracy: 0.8555\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3409 - accuracy: 0.8585 - val_loss: 0.3921 - val_accuracy: 0.8315\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3365 - accuracy: 0.8584 - val_loss: 0.3786 - val_accuracy: 0.8470\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3354 - accuracy: 0.8594 - val_loss: 0.3730 - val_accuracy: 0.8455\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3358 - accuracy: 0.8634 - val_loss: 0.3638 - val_accuracy: 0.8525\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3385 - accuracy: 0.8576 - val_loss: 0.3776 - val_accuracy: 0.8435\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3359 - accuracy: 0.8577 - val_loss: 0.3907 - val_accuracy: 0.8385\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8636 - val_loss: 0.3634 - val_accuracy: 0.8500\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3330 - accuracy: 0.8650 - val_loss: 0.3796 - val_accuracy: 0.8375\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3332 - accuracy: 0.8649 - val_loss: 0.3747 - val_accuracy: 0.8465\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3361 - accuracy: 0.8579 - val_loss: 0.3744 - val_accuracy: 0.8420\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.8639 - val_loss: 0.3854 - val_accuracy: 0.8380\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8621 - val_loss: 0.3718 - val_accuracy: 0.8485\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8641 - val_loss: 0.3869 - val_accuracy: 0.8360\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.3302 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8649 - val_loss: 0.4060 - val_accuracy: 0.8360\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8627 - val_loss: 0.3944 - val_accuracy: 0.8410\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3268 - accuracy: 0.8635 - val_loss: 0.3619 - val_accuracy: 0.8530\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3257 - accuracy: 0.8643 - val_loss: 0.3563 - val_accuracy: 0.8505\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8655 - val_loss: 0.3672 - val_accuracy: 0.8525\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3215 - accuracy: 0.8680 - val_loss: 0.3657 - val_accuracy: 0.8530\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3214 - accuracy: 0.8684 - val_loss: 0.3674 - val_accuracy: 0.8530\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3221 - accuracy: 0.8652 - val_loss: 0.3796 - val_accuracy: 0.8420\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3196 - accuracy: 0.8625 - val_loss: 0.3725 - val_accuracy: 0.8540\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3203 - accuracy: 0.8648 - val_loss: 0.3580 - val_accuracy: 0.8570\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3220 - accuracy: 0.8654 - val_loss: 0.4105 - val_accuracy: 0.8405\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3221 - accuracy: 0.8660 - val_loss: 0.4019 - val_accuracy: 0.8340\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3161 - accuracy: 0.8696 - val_loss: 0.3594 - val_accuracy: 0.8530\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3188 - accuracy: 0.8689 - val_loss: 0.3786 - val_accuracy: 0.8430\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3172 - accuracy: 0.8691 - val_loss: 0.3929 - val_accuracy: 0.8380\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3180 - accuracy: 0.8645 - val_loss: 0.3896 - val_accuracy: 0.8365\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3140 - accuracy: 0.8684 - val_loss: 0.4008 - val_accuracy: 0.8425\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3141 - accuracy: 0.8658 - val_loss: 0.3666 - val_accuracy: 0.8495\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3125 - accuracy: 0.8656 - val_loss: 0.3682 - val_accuracy: 0.8490\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3104 - accuracy: 0.8705 - val_loss: 0.3784 - val_accuracy: 0.8410\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3101 - accuracy: 0.8686 - val_loss: 0.4203 - val_accuracy: 0.8190\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3119 - accuracy: 0.8679 - val_loss: 0.3799 - val_accuracy: 0.8440\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3116 - accuracy: 0.8705 - val_loss: 0.3959 - val_accuracy: 0.8445\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3104 - accuracy: 0.8691 - val_loss: 0.3697 - val_accuracy: 0.8490\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3100 - accuracy: 0.8686 - val_loss: 0.3884 - val_accuracy: 0.8395\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3094 - accuracy: 0.8700 - val_loss: 0.3861 - val_accuracy: 0.8440\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3086 - accuracy: 0.8686 - val_loss: 0.3843 - val_accuracy: 0.8460\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3071 - accuracy: 0.8702 - val_loss: 0.3814 - val_accuracy: 0.8435\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3072 - accuracy: 0.8694 - val_loss: 0.3658 - val_accuracy: 0.8505\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3072 - accuracy: 0.8715 - val_loss: 0.3856 - val_accuracy: 0.8485\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3050 - accuracy: 0.8715 - val_loss: 0.3703 - val_accuracy: 0.8500\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3034 - accuracy: 0.8724 - val_loss: 0.3767 - val_accuracy: 0.8545\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3020 - accuracy: 0.8760 - val_loss: 0.4220 - val_accuracy: 0.8490\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2974 - accuracy: 0.8746 - val_loss: 0.3800 - val_accuracy: 0.8400\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2999 - accuracy: 0.8712 - val_loss: 0.3729 - val_accuracy: 0.8500\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2993 - accuracy: 0.8748 - val_loss: 0.4158 - val_accuracy: 0.8275\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2963 - accuracy: 0.8720 - val_loss: 0.3891 - val_accuracy: 0.8485\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2935 - accuracy: 0.8736 - val_loss: 0.4004 - val_accuracy: 0.8440\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2996 - accuracy: 0.8706 - val_loss: 0.3786 - val_accuracy: 0.8530\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2961 - accuracy: 0.8765 - val_loss: 0.3777 - val_accuracy: 0.8450\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2943 - accuracy: 0.8752 - val_loss: 0.3874 - val_accuracy: 0.8470\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2906 - accuracy: 0.8771 - val_loss: 0.4271 - val_accuracy: 0.8375\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2930 - accuracy: 0.8742 - val_loss: 0.3952 - val_accuracy: 0.8395\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2950 - accuracy: 0.8773 - val_loss: 0.3823 - val_accuracy: 0.8460\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2910 - accuracy: 0.8727 - val_loss: 0.3978 - val_accuracy: 0.8390\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2841 - accuracy: 0.8816 - val_loss: 0.4004 - val_accuracy: 0.8360\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2863 - accuracy: 0.8790 - val_loss: 0.4328 - val_accuracy: 0.8310\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2887 - accuracy: 0.8759 - val_loss: 0.3783 - val_accuracy: 0.8545\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2912 - accuracy: 0.8783 - val_loss: 0.3913 - val_accuracy: 0.8470\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2804 - accuracy: 0.8823 - val_loss: 0.3881 - val_accuracy: 0.8470\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2897 - accuracy: 0.8784 - val_loss: 0.4274 - val_accuracy: 0.8440\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2809 - accuracy: 0.8795 - val_loss: 0.4026 - val_accuracy: 0.8400\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2835 - accuracy: 0.8789 - val_loss: 0.4096 - val_accuracy: 0.8425\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2871 - accuracy: 0.8756 - val_loss: 0.4034 - val_accuracy: 0.8335\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2812 - accuracy: 0.8849 - val_loss: 0.4166 - val_accuracy: 0.8300\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2760 - accuracy: 0.8809 - val_loss: 0.4166 - val_accuracy: 0.8435\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2815 - accuracy: 0.8798 - val_loss: 0.3955 - val_accuracy: 0.8440\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2874 - accuracy: 0.8775 - val_loss: 0.4160 - val_accuracy: 0.8405\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2796 - accuracy: 0.8817 - val_loss: 0.3974 - val_accuracy: 0.8375\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2786 - accuracy: 0.8791 - val_loss: 0.4097 - val_accuracy: 0.8350\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2812 - accuracy: 0.8781 - val_loss: 0.4065 - val_accuracy: 0.8335\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2783 - accuracy: 0.8806 - val_loss: 0.3970 - val_accuracy: 0.8515\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2751 - accuracy: 0.8800 - val_loss: 0.4020 - val_accuracy: 0.8375\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2730 - accuracy: 0.8825 - val_loss: 0.4214 - val_accuracy: 0.8340\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2709 - accuracy: 0.8867 - val_loss: 0.4063 - val_accuracy: 0.8320\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2716 - accuracy: 0.8841 - val_loss: 0.4485 - val_accuracy: 0.8290\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2755 - accuracy: 0.8810 - val_loss: 0.4285 - val_accuracy: 0.8405\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.2701 - accuracy: 0.8846 - val_loss: 0.4188 - val_accuracy: 0.8320\n"
     ]
    }
   ],
   "source": [
    "#Fitting the model with the training data and validation with testing data\n",
    "\n",
    "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "58e7c805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.896, Test: 0.832\n"
     ]
    }
   ],
   "source": [
    "#Checking the model accuracy\n",
    "\n",
    "_, train_acc = model.evaluate(X_train, Y_train, verbose=0)\n",
    "_, test_acc = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5201c5e9",
   "metadata": {},
   "source": [
    "## We see that after standardizing our data, we get a very good fit model which is much better than our previous model. Thus, from this we conclude that for this given data it is better to standardize the data before building the nueral network instead of relying only on the batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ee36f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d45a958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "133e2868",
   "metadata": {},
   "source": [
    "# Checking the performance by decreasing the number of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1e43bdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256,input_dim = 12, activation='relu'))\n",
    "\n",
    "model.add(Dense(32,activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "630e017c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 0s 941us/step - loss: 0.4984 - accuracy: 0.7891 - val_loss: 0.4686 - val_accuracy: 0.7925\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 0s 600us/step - loss: 0.4622 - accuracy: 0.7999 - val_loss: 0.5453 - val_accuracy: 0.7275\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 0s 575us/step - loss: 0.4521 - accuracy: 0.8066 - val_loss: 0.4593 - val_accuracy: 0.7965\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 0s 572us/step - loss: 0.4523 - accuracy: 0.8035 - val_loss: 0.4647 - val_accuracy: 0.8010\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 0s 580us/step - loss: 0.4399 - accuracy: 0.8101 - val_loss: 0.4535 - val_accuracy: 0.7970\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 0s 577us/step - loss: 0.4383 - accuracy: 0.8112 - val_loss: 0.4463 - val_accuracy: 0.7980\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 0s 581us/step - loss: 0.4468 - accuracy: 0.8052 - val_loss: 0.4579 - val_accuracy: 0.8035\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 0s 576us/step - loss: 0.4289 - accuracy: 0.8179 - val_loss: 0.4428 - val_accuracy: 0.8070\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 0s 578us/step - loss: 0.4282 - accuracy: 0.8161 - val_loss: 0.4621 - val_accuracy: 0.7970\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 0s 577us/step - loss: 0.4218 - accuracy: 0.8164 - val_loss: 0.4695 - val_accuracy: 0.7845\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 0s 585us/step - loss: 0.4195 - accuracy: 0.8179 - val_loss: 0.4301 - val_accuracy: 0.8090\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 0s 589us/step - loss: 0.4158 - accuracy: 0.8201 - val_loss: 0.4405 - val_accuracy: 0.8055\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 0s 593us/step - loss: 0.4043 - accuracy: 0.8241 - val_loss: 0.4329 - val_accuracy: 0.8080\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 0s 571us/step - loss: 0.4020 - accuracy: 0.8278 - val_loss: 0.4162 - val_accuracy: 0.8175\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 0s 594us/step - loss: 0.3911 - accuracy: 0.8325 - val_loss: 0.4047 - val_accuracy: 0.8255\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 0s 596us/step - loss: 0.3907 - accuracy: 0.8328 - val_loss: 0.4264 - val_accuracy: 0.8115\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 0s 593us/step - loss: 0.3779 - accuracy: 0.8429 - val_loss: 0.3971 - val_accuracy: 0.8320\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 0s 597us/step - loss: 0.3721 - accuracy: 0.8436 - val_loss: 0.3912 - val_accuracy: 0.8305\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 0s 601us/step - loss: 0.3676 - accuracy: 0.8461 - val_loss: 0.3936 - val_accuracy: 0.8300\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 0s 601us/step - loss: 0.3651 - accuracy: 0.8471 - val_loss: 0.3821 - val_accuracy: 0.8360\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 0s 593us/step - loss: 0.3614 - accuracy: 0.8489 - val_loss: 0.3790 - val_accuracy: 0.8415\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 0s 597us/step - loss: 0.3567 - accuracy: 0.8519 - val_loss: 0.3896 - val_accuracy: 0.8435\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 0s 589us/step - loss: 0.3551 - accuracy: 0.8525 - val_loss: 0.3806 - val_accuracy: 0.8365\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 0s 584us/step - loss: 0.3563 - accuracy: 0.8505 - val_loss: 0.3748 - val_accuracy: 0.8420\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 0s 596us/step - loss: 0.3507 - accuracy: 0.8544 - val_loss: 0.3720 - val_accuracy: 0.8435\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 0s 593us/step - loss: 0.3485 - accuracy: 0.8536 - val_loss: 0.3791 - val_accuracy: 0.8500\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 0s 577us/step - loss: 0.3492 - accuracy: 0.8528 - val_loss: 0.3728 - val_accuracy: 0.8455\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 0s 589us/step - loss: 0.3449 - accuracy: 0.8547 - val_loss: 0.3730 - val_accuracy: 0.8425\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 0s 589us/step - loss: 0.3442 - accuracy: 0.8584 - val_loss: 0.3776 - val_accuracy: 0.8400\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 0s 589us/step - loss: 0.3456 - accuracy: 0.8554 - val_loss: 0.3747 - val_accuracy: 0.8415\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 0s 593us/step - loss: 0.3433 - accuracy: 0.8549 - val_loss: 0.3803 - val_accuracy: 0.8340\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 0s 597us/step - loss: 0.3412 - accuracy: 0.8568 - val_loss: 0.3711 - val_accuracy: 0.8405\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 0s 601us/step - loss: 0.3395 - accuracy: 0.8591 - val_loss: 0.3712 - val_accuracy: 0.8485\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 0s 597us/step - loss: 0.3382 - accuracy: 0.8606 - val_loss: 0.3802 - val_accuracy: 0.8370\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 0s 597us/step - loss: 0.3373 - accuracy: 0.8604 - val_loss: 0.3719 - val_accuracy: 0.8405\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 0s 591us/step - loss: 0.3359 - accuracy: 0.8609 - val_loss: 0.3779 - val_accuracy: 0.8425\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 0s 582us/step - loss: 0.3393 - accuracy: 0.8547 - val_loss: 0.3808 - val_accuracy: 0.8480\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 0s 590us/step - loss: 0.3349 - accuracy: 0.8600 - val_loss: 0.3666 - val_accuracy: 0.8470\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 0s 584us/step - loss: 0.3341 - accuracy: 0.8596 - val_loss: 0.3693 - val_accuracy: 0.8460\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 0s 582us/step - loss: 0.3333 - accuracy: 0.8590 - val_loss: 0.3888 - val_accuracy: 0.8315\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 0s 588us/step - loss: 0.3291 - accuracy: 0.8625 - val_loss: 0.3730 - val_accuracy: 0.8435\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 0s 579us/step - loss: 0.3316 - accuracy: 0.8614 - val_loss: 0.3829 - val_accuracy: 0.8445\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 0s 583us/step - loss: 0.3291 - accuracy: 0.8650 - val_loss: 0.3832 - val_accuracy: 0.8390\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 0s 584us/step - loss: 0.3304 - accuracy: 0.8650 - val_loss: 0.3820 - val_accuracy: 0.8285\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 0s 574us/step - loss: 0.3295 - accuracy: 0.8670 - val_loss: 0.3830 - val_accuracy: 0.8310\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 0s 583us/step - loss: 0.3292 - accuracy: 0.8619 - val_loss: 0.3693 - val_accuracy: 0.8470\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 0s 578us/step - loss: 0.3278 - accuracy: 0.8630 - val_loss: 0.3665 - val_accuracy: 0.8490\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 0s 584us/step - loss: 0.3256 - accuracy: 0.8645 - val_loss: 0.3736 - val_accuracy: 0.8435\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 0s 574us/step - loss: 0.3235 - accuracy: 0.8652 - val_loss: 0.3723 - val_accuracy: 0.8460\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 0s 588us/step - loss: 0.3217 - accuracy: 0.8654 - val_loss: 0.3749 - val_accuracy: 0.8505\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 0s 589us/step - loss: 0.3247 - accuracy: 0.8661 - val_loss: 0.3915 - val_accuracy: 0.8480\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 0s 575us/step - loss: 0.3235 - accuracy: 0.8658 - val_loss: 0.3901 - val_accuracy: 0.8440\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 0s 575us/step - loss: 0.3227 - accuracy: 0.8665 - val_loss: 0.3699 - val_accuracy: 0.8410\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 0s 582us/step - loss: 0.3204 - accuracy: 0.8654 - val_loss: 0.3719 - val_accuracy: 0.8400\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 0s 574us/step - loss: 0.3182 - accuracy: 0.8664 - val_loss: 0.3755 - val_accuracy: 0.8415\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 0s 574us/step - loss: 0.3194 - accuracy: 0.8679 - val_loss: 0.3662 - val_accuracy: 0.8480\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 580us/step - loss: 0.3175 - accuracy: 0.8681 - val_loss: 0.3686 - val_accuracy: 0.8435\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 0s 574us/step - loss: 0.3167 - accuracy: 0.8683 - val_loss: 0.3686 - val_accuracy: 0.8465\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 0s 574us/step - loss: 0.3170 - accuracy: 0.8702 - val_loss: 0.3819 - val_accuracy: 0.8415\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 0s 583us/step - loss: 0.3177 - accuracy: 0.8664 - val_loss: 0.3686 - val_accuracy: 0.8450\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 0s 578us/step - loss: 0.3163 - accuracy: 0.8681 - val_loss: 0.3757 - val_accuracy: 0.8430\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 0s 577us/step - loss: 0.3164 - accuracy: 0.8692 - val_loss: 0.3687 - val_accuracy: 0.8480\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 0s 572us/step - loss: 0.3122 - accuracy: 0.8687 - val_loss: 0.3792 - val_accuracy: 0.8400\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 0s 575us/step - loss: 0.3142 - accuracy: 0.8692 - val_loss: 0.3712 - val_accuracy: 0.8485\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 0s 583us/step - loss: 0.3114 - accuracy: 0.8686 - val_loss: 0.3826 - val_accuracy: 0.8430\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 0s 583us/step - loss: 0.3117 - accuracy: 0.8680 - val_loss: 0.3765 - val_accuracy: 0.8410\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 0s 582us/step - loss: 0.3071 - accuracy: 0.8726 - val_loss: 0.3865 - val_accuracy: 0.8440\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 0s 578us/step - loss: 0.3106 - accuracy: 0.8702 - val_loss: 0.3735 - val_accuracy: 0.8510\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 0s 579us/step - loss: 0.3050 - accuracy: 0.8739 - val_loss: 0.3820 - val_accuracy: 0.8490\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 0s 574us/step - loss: 0.3080 - accuracy: 0.8710 - val_loss: 0.3712 - val_accuracy: 0.8445\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 0s 582us/step - loss: 0.3048 - accuracy: 0.8737 - val_loss: 0.3936 - val_accuracy: 0.8425\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 0s 580us/step - loss: 0.3047 - accuracy: 0.8733 - val_loss: 0.3819 - val_accuracy: 0.8475\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 0s 574us/step - loss: 0.3027 - accuracy: 0.8741 - val_loss: 0.3736 - val_accuracy: 0.8470\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 0s 572us/step - loss: 0.3013 - accuracy: 0.8735 - val_loss: 0.3732 - val_accuracy: 0.8375\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 0s 573us/step - loss: 0.3020 - accuracy: 0.8737 - val_loss: 0.3843 - val_accuracy: 0.8430\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 0s 587us/step - loss: 0.3024 - accuracy: 0.8751 - val_loss: 0.3764 - val_accuracy: 0.8515\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 0s 570us/step - loss: 0.3019 - accuracy: 0.8731 - val_loss: 0.3734 - val_accuracy: 0.8495\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 0s 581us/step - loss: 0.3007 - accuracy: 0.8740 - val_loss: 0.3754 - val_accuracy: 0.8480\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 0s 580us/step - loss: 0.3000 - accuracy: 0.8730 - val_loss: 0.4003 - val_accuracy: 0.8410\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 0s 575us/step - loss: 0.2991 - accuracy: 0.8741 - val_loss: 0.3778 - val_accuracy: 0.8370\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 0s 578us/step - loss: 0.2987 - accuracy: 0.8721 - val_loss: 0.3758 - val_accuracy: 0.8455\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 0s 578us/step - loss: 0.2954 - accuracy: 0.8759 - val_loss: 0.3832 - val_accuracy: 0.8430\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 0s 578us/step - loss: 0.2971 - accuracy: 0.8761 - val_loss: 0.3744 - val_accuracy: 0.8535\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 0s 591us/step - loss: 0.2943 - accuracy: 0.8771 - val_loss: 0.3788 - val_accuracy: 0.8485\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 0s 578us/step - loss: 0.2937 - accuracy: 0.8783 - val_loss: 0.3801 - val_accuracy: 0.8450\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 0s 582us/step - loss: 0.2910 - accuracy: 0.8756 - val_loss: 0.3748 - val_accuracy: 0.8465\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 0s 578us/step - loss: 0.2931 - accuracy: 0.8752 - val_loss: 0.3854 - val_accuracy: 0.8445\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 0s 570us/step - loss: 0.2949 - accuracy: 0.8752 - val_loss: 0.3841 - val_accuracy: 0.8485\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 0s 575us/step - loss: 0.2886 - accuracy: 0.8792 - val_loss: 0.3821 - val_accuracy: 0.8485\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 0s 571us/step - loss: 0.2941 - accuracy: 0.8771 - val_loss: 0.3819 - val_accuracy: 0.8455\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 0s 575us/step - loss: 0.2867 - accuracy: 0.8791 - val_loss: 0.3852 - val_accuracy: 0.8460\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 0s 582us/step - loss: 0.2873 - accuracy: 0.8786 - val_loss: 0.3898 - val_accuracy: 0.8460\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 0s 579us/step - loss: 0.2858 - accuracy: 0.8815 - val_loss: 0.3995 - val_accuracy: 0.8455\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 0s 584us/step - loss: 0.2874 - accuracy: 0.8780 - val_loss: 0.3961 - val_accuracy: 0.8440\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 0s 576us/step - loss: 0.2885 - accuracy: 0.8764 - val_loss: 0.3930 - val_accuracy: 0.8490\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 0s 577us/step - loss: 0.2829 - accuracy: 0.8808 - val_loss: 0.3934 - val_accuracy: 0.8410\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 0s 569us/step - loss: 0.2826 - accuracy: 0.8794 - val_loss: 0.3973 - val_accuracy: 0.8355\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 0s 580us/step - loss: 0.2817 - accuracy: 0.8808 - val_loss: 0.3877 - val_accuracy: 0.8540\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 0s 621us/step - loss: 0.2820 - accuracy: 0.8809 - val_loss: 0.3812 - val_accuracy: 0.8505\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 0s 615us/step - loss: 0.2807 - accuracy: 0.8814 - val_loss: 0.4093 - val_accuracy: 0.8455\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b45d2c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.885, Test: 0.845\n"
     ]
    }
   ],
   "source": [
    "_, train_acc = model.evaluate(X_train, Y_train, verbose=0)\n",
    "_, test_acc = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b859b424",
   "metadata": {},
   "source": [
    "## Here we see that as we decreased our number of layers for the data, the training accuracy has decreased a little, while the testing accuracy has improved a little bit. Comparing with the above model, this model is better as it has lower chance of overfitting in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d3fcdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51fa24f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dba5001c",
   "metadata": {},
   "source": [
    "## Changing the Optimizer in the nueral network (SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7aafe3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Yeshwanth\\Anaconda\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256,input_dim = 12, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(16,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Using Stochastic Gradient Descent as optimizer instead of adam\n",
    "opt = SGD(lr = 0.01, momentum = 0.9)\n",
    "model.compile(loss='binary_crossentropy',optimizer=opt,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c67a6485",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f2f2e65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.802, Test: 0.800\n"
     ]
    }
   ],
   "source": [
    "_, train_acc = model.evaluate(X_train, Y_train, verbose=0)\n",
    "_, test_acc = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0d1089",
   "metadata": {},
   "source": [
    "## We see that using SGD over Adam has decreased the performance for both training and testing datasets. So ADAM is preffered over SGD for this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911c084f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b11804a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2656998c",
   "metadata": {},
   "source": [
    "## Changing the optimizer (RMSProp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "62dc70b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256,input_dim = 12, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(16,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Using RMSProp as the optimizer\n",
    "model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ab0ad1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "66a08bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.892, Test: 0.855\n"
     ]
    }
   ],
   "source": [
    "_, train_acc = model.evaluate(X_train, Y_train, verbose=0)\n",
    "_, test_acc = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb40835",
   "metadata": {},
   "source": [
    "## We see that by using RMSProp over ADAM, both the training and testing performance has improved much better. Thus for this data, RMSProp is better than ADAM as optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70f28af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c8827c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a060da55",
   "metadata": {},
   "source": [
    "## Using Dropout to remove unnecessary parameters in subsequent layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f604f47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256,input_dim = 12, activation='relu'))  #Using dropout to remove unnecessary parameters (weights and biases)\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c31a8760",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "44fe0913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.855, Test: 0.837\n"
     ]
    }
   ],
   "source": [
    "_, train_acc = model.evaluate(X_train, Y_train, verbose=0)\n",
    "_, test_acc = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c827fcfc",
   "metadata": {},
   "source": [
    "## We observe that using Dropout for this model has not given better results than the previous ones. So for this model, Dropout is not necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443bf37a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b66da297",
   "metadata": {},
   "source": [
    "# SUMMARY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee19a38",
   "metadata": {},
   "source": [
    "## From the above, we observe that:\n",
    "\n",
    "## 1) It is better to standardize the data before building the nueral model, instead of relying completely on Batch Normaliztion.\n",
    "\n",
    "## 2) RMSProp as optimizer showed better results than ADAM and SGD.\n",
    "\n",
    "## 3) There was no need of Dropout in the model\n",
    "\n",
    "## 4) The model was a good fit model with very good performance around 89% for training and 85% for testing which was neither overfitting nor underfitting\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b3a033",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e63ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f97661a0",
   "metadata": {},
   "source": [
    "# CONCLUSION:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7ced16",
   "metadata": {},
   "source": [
    "## The performance of a nueral model depends very much on the data we provide to it and it is better to evaluate for different models with different hyperparameters to come up with the best fit model instead of relying by evaluating of only one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5970a6d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd61550",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be15c37b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b535d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8588daa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff09f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
